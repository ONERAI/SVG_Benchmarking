Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 50
Rules claiming more threads will be scaled down.
Job stats:
job          count    min threads    max threads
---------  -------  -------------  -------------
all              1              1              1
run_SPARK        5             10             10
total            6              1             10

Select jobs to execute...

[Sun Jul 16 14:42:23 2023]
rule run_SPARK:
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E12_5_rep1.h5ad
    output: results/spatial_atac/SPARK/E12_5_rep1.csv
    jobid: 1
    benchmark: benchmarks/spatial_atac/SPARK/E12_5_rep1.txt
    reason: Missing output files: results/spatial_atac/SPARK/E12_5_rep1.csv
    wildcards: dataset=E12_5_rep1
    threads: 10
    resources: tmpdir=/tmp


[Sun Jul 16 14:42:23 2023]
rule run_SPARK:
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E13_5_rep2.h5ad
    output: results/spatial_atac/SPARK/E13_5_rep2.csv
    jobid: 3
    benchmark: benchmarks/spatial_atac/SPARK/E13_5_rep2.txt
    reason: Missing output files: results/spatial_atac/SPARK/E13_5_rep2.csv
    wildcards: dataset=E13_5_rep2
    threads: 10
    resources: tmpdir=/tmp


[Sun Jul 16 14:42:23 2023]
rule run_SPARK:
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E15_5_rep1.h5ad
    output: results/spatial_atac/SPARK/E15_5_rep1.csv
    jobid: 4
    benchmark: benchmarks/spatial_atac/SPARK/E15_5_rep1.txt
    reason: Missing output files: results/spatial_atac/SPARK/E15_5_rep1.csv
    wildcards: dataset=E15_5_rep1
    threads: 10
    resources: tmpdir=/tmp


[Sun Jul 16 14:42:23 2023]
rule run_SPARK:
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E12_5_rep2.h5ad
    output: results/spatial_atac/SPARK/E12_5_rep2.csv
    jobid: 2
    benchmark: benchmarks/spatial_atac/SPARK/E12_5_rep2.txt
    reason: Missing output files: results/spatial_atac/SPARK/E12_5_rep2.csv
    wildcards: dataset=E12_5_rep2
    threads: 10
    resources: tmpdir=/tmp


[Sun Jul 16 14:42:23 2023]
rule run_SPARK:
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E15_5_rep2.h5ad
    output: results/spatial_atac/SPARK/E15_5_rep2.csv
    jobid: 5
    benchmark: benchmarks/spatial_atac/SPARK/E15_5_rep2.txt
    reason: Missing output files: results/spatial_atac/SPARK/E15_5_rep2.csv
    wildcards: dataset=E15_5_rep2
    threads: 10
    resources: tmpdir=/tmp

Activating conda environment: SPARK
Activating conda environment: SPARK
Activating conda environment: SPARK
Activating conda environment: SPARK
Activating conda environment: SPARK
Will exit after finishing currently running jobs (scheduler).
[Sun Jul 16 15:12:27 2023]
Error in rule run_SPARK:
    jobid: 3
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E13_5_rep2.h5ad
    output: results/spatial_atac/SPARK/E13_5_rep2.csv
    conda-env: SPARK
    shell:
        Rscript scripts/spatial_atac/run_SPARK.R -i /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E13_5_rep2.h5ad -o results/spatial_atac/SPARK/E13_5_rep2.csv
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

[Sun Jul 16 15:12:27 2023]
[Sun Jul 16 15:12:27 2023]
Error in rule run_SPARK:
    jobid: 1
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E12_5_rep1.h5ad
    output: results/spatial_atac/SPARK/E12_5_rep1.csv
    conda-env: SPARK
    shell:
        Rscript scripts/spatial_atac/run_SPARK.R -i /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E12_5_rep1.h5ad -o results/spatial_atac/SPARK/E12_5_rep1.csv
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Error in rule run_SPARK:
    jobid: 4
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E15_5_rep1.h5ad
    output: results/spatial_atac/SPARK/E15_5_rep1.csv
    conda-env: SPARK
    shell:
        Rscript scripts/spatial_atac/run_SPARK.R -i /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E15_5_rep1.h5ad -o results/spatial_atac/SPARK/E15_5_rep1.csv
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

[Sun Jul 16 15:12:27 2023]
Will exit after finishing currently running jobs (scheduler).
Error in rule run_SPARK:
    jobid: 5
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E15_5_rep2.h5ad
    output: results/spatial_atac/SPARK/E15_5_rep2.csv
    conda-env: SPARK
    shell:
        Rscript scripts/spatial_atac/run_SPARK.R -i /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E15_5_rep2.h5ad -o results/spatial_atac/SPARK/E15_5_rep2.csv
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

[Sun Jul 16 15:12:27 2023]
Error in rule run_SPARK:
    jobid: 2
    input: /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E12_5_rep2.h5ad
    output: results/spatial_atac/SPARK/E12_5_rep2.csv
    conda-env: SPARK
    shell:
        Rscript scripts/spatial_atac/run_SPARK.R -i /data/pinello/PROJECTS/2023_03_SVGBenchmarking/SpatialATAC/ProcessedData/AnnData/Enric_NBT_2023/E12_5_rep2.h5ad -o results/spatial_atac/SPARK/E12_5_rep2.csv
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Will exit after finishing currently running jobs (scheduler).
Will exit after finishing currently running jobs (scheduler).
Shutting down, this might take some time.
Complete log: .snakemake/log/2023-07-16T144221.422814.snakemake.log
